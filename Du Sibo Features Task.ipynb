{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART1: 5 New Features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Investor Irrationality \n",
    "\n",
    "Investor irrationality is a significant factor influencing asset price formation. By constructing an \"irrational belief measure,\" some paper finds that the irrational belief measure has negative predictive power for future returns.\n",
    "\n",
    "First, construct the investor irrational beliefs using a turnover separation model. The model posits that investor trading behavior is driven by three factors: the first factor is the investor's exogenous liquidity demand; the second is rational trading behavior based on the firm's fundamental value; the third is irrational beliefs unrelated to fundamental value. The expression is:\n",
    "\n",
    "$ TO = E[\\text{trading} | \\text{Eliq}] + E[\\text{trading} | D] + E[\\text{trading} | \\text{IRB}] $\n",
    "\n",
    "where:\n",
    "\n",
    "- $( E[\\text{trading} | \\text{Eliq}] )$ represents trading driven by different beliefs, reflected through turnover rate.\n",
    "- $( E[\\text{trading} | D] )$ represents rational investor beliefs driven by fundamental value, using four indicators: Return on Assets (ROA), Total Asset Growth Rate (INV), Cash Flow (CASH), and Stock Size (SIZE).\n",
    "- $( E[\\text{trading} | \\text{IRB}] )$ represents the proxy for irrational beliefs, i.e., the \"irrational belief measure.\"\n",
    "\n",
    "Then, the irrational belief measure is deduced as:\n",
    "\n",
    "$$ E[\\text{trading} | \\text{IRB}] = TO - E[\\text{trading} | \\text{Eliq}] - E[\\text{trading} | D] $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   turnover_rate  liquidity_needs  rational_trading  irrational_belief\n",
      "0           0.10            0.020           0.03500            0.04500\n",
      "1           0.20            0.030           0.04500            0.12500\n",
      "2           0.15            0.025           0.04375            0.08125\n",
      "3           0.30            0.040           0.05500            0.20500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'turnover_rate', 'liquidity_needs', 'ROA', 'INV', 'CASH', 'SIZE' are columns in your DataFrame\n",
    "\n",
    "def calculate_irrational_belief(df):\n",
    "    # Calculate the rational trading component based on fundamental values\n",
    "    # We could do linear regression of the historical return on these 4 fundamental values to get the coefficient\n",
    "    # Here for simplicity, I assume the coefficient is the same.\n",
    "    df['rational_trading'] = (df['ROA'] + df['INV'] + df['CASH'] + df['SIZE']) / 4\n",
    "    \n",
    "    # Calculate the irrational belief measure\n",
    "    df['irrational_belief'] = df['turnover_rate'] - df['liquidity_needs'] - df['rational_trading']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "data = {\n",
    "    'turnover_rate': [0.1, 0.2, 0.15, 0.3],\n",
    "    'liquidity_needs': [0.02, 0.03, 0.025, 0.04],\n",
    "    'ROA': [0.05, 0.06, 0.07, 0.08],\n",
    "    'INV': [0.02, 0.03, 0.025, 0.04],\n",
    "    'CASH': [0.03, 0.04, 0.035, 0.045],\n",
    "    'SIZE': [0.04, 0.05, 0.045, 0.055]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate irrational belief measure\n",
    "df = calculate_irrational_belief(df)\n",
    "print(df[['turnover_rate', 'liquidity_needs', 'rational_trading', 'irrational_belief']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Social Media Buzz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Social Media Buzz feature tracks the volume of social media mentions and discussions about a particular stock. High levels of buzz can indicate increased interest and potential volatility. This feature provides insights into market trends influenced by public sentiment and hype.\n",
    "\n",
    "#### Potential Methods for Implementation\n",
    "\n",
    "1. **Volume of Mentions**: Track the number of mentions of the stock ticker on popular social media platforms (e.g., Twitter, Reddit, StockTwits) over a given time period.\n",
    "2. **Sentiment Analysis**: Analyze the sentiment (positive, negative, neutral) of the social media mentions to understand the overall market mood towards the stock.\n",
    "3. **Trend Analysis**: Use moving averages to track the trend in the volume of mentions over time.\n",
    "4. **Frequency Analysis**: Calculate the frequency of keywords associated with the stock within social media posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Volume of Mentions**:\n",
    "   $$\n",
    "   \\text{Volume of Mentions} = \\sum_{i=1}^{N} \\text{Mentions}_{i}\n",
    "   $$\n",
    "   where \\(N\\) is the number of social media posts mentioning the stock within a given time period.\n",
    "\n",
    "2. **Sentiment Analysis**:\n",
    "   $$\n",
    "   \\text{Sentiment Score} = \\frac{\\sum_{i=1}^{N} \\text{Sentiment}_{i} \\times \\text{Mentions}_{i}}{\\text{Volume of Mentions}}\n",
    "   $$\n",
    "   where $\\text{Sentiment}_{i}$ is the sentiment score of each mention (e.g., +1 for positive, -1 for negative, 0 for neutral).\n",
    "\n",
    "3. **Trend Analysis (Moving Average)**:\n",
    "   $$\n",
    "   \\text{Moving Average}_{t} = \\frac{1}{k} \\sum_{i=0}^{k-1} \\text{Volume of Mentions}_{t-i}\n",
    "   $$\n",
    "   where \\(k\\) is the window size for the moving average.\n",
    "\n",
    "4. **Frequency Analysis**:\n",
    "   $$\n",
    "   \\text{Keyword Frequency} = \\frac{\\text{Number of Keyword Occurrences}}{\\text{Total Number of Words}}\n",
    "   $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume of Mentions:\n",
      " timestamp\n",
      "2023-07-01 12:00:00    1\n",
      "2023-07-01 12:05:00    1\n",
      "2023-07-01 12:10:00    1\n",
      "2023-07-01 12:15:00    1\n",
      "2023-07-01 12:20:00    1\n",
      "Freq: 5min, dtype: int64\n",
      "\n",
      "Average Sentiment:\n",
      " timestamp\n",
      "2023-07-01 12:00:00    0.00\n",
      "2023-07-01 12:05:00   -0.35\n",
      "2023-07-01 12:10:00    0.50\n",
      "2023-07-01 12:15:00    0.00\n",
      "2023-07-01 12:20:00    0.00\n",
      "Freq: 5min, Name: sentiment, dtype: float64\n",
      "\n",
      "Moving Average of Mentions:\n",
      " timestamp\n",
      "2023-07-01 12:00:00    NaN\n",
      "2023-07-01 12:05:00    NaN\n",
      "2023-07-01 12:10:00    1.0\n",
      "2023-07-01 12:15:00    1.0\n",
      "2023-07-01 12:20:00    1.0\n",
      "Freq: 5min, dtype: float64\n",
      "\n",
      "Social Media Buzz Features:\n",
      "                      Volume of Mentions  Average Sentiment  \\\n",
      "timestamp                                                    \n",
      "2023-07-01 12:00:00                   1               0.00   \n",
      "2023-07-01 12:05:00                   1              -0.35   \n",
      "2023-07-01 12:10:00                   1               0.50   \n",
      "2023-07-01 12:15:00                   1               0.00   \n",
      "2023-07-01 12:20:00                   1               0.00   \n",
      "\n",
      "                     Moving Average Mentions  \n",
      "timestamp                                     \n",
      "2023-07-01 12:00:00                      0.0  \n",
      "2023-07-01 12:05:00                      0.0  \n",
      "2023-07-01 12:10:00                      1.0  \n",
      "2023-07-01 12:15:00                      1.0  \n",
      "2023-07-01 12:20:00                      1.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dusib\\AppData\\Local\\Temp\\ipykernel_29492\\3034930348.py:38: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  volume_of_mentions = df.resample('5T').size()\n",
      "C:\\Users\\dusib\\AppData\\Local\\Temp\\ipykernel_29492\\3034930348.py:41: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  average_sentiment = df.resample('5T')['sentiment'].mean()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import datetime\n",
    "\n",
    "# Example DataFrame containing social media posts\n",
    "data = {\n",
    "    'timestamp': [\n",
    "        '2023-07-01 12:00:00', '2023-07-01 12:05:00', '2023-07-01 12:10:00', \n",
    "        '2023-07-01 12:15:00', '2023-07-01 12:20:00'\n",
    "    ],\n",
    "    'post': [\n",
    "        \"I think AAPL is going to skyrocket!\", \"AAPL is such a bad investment...\",\n",
    "        \"I'm buying more AAPL stocks\", \"AAPL is neutral for me\", \"AAPL to the moon!\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Define the stock ticker\n",
    "ticker = \"AAPL\"\n",
    "\n",
    "# Define function to calculate sentiment score\n",
    "def get_sentiment(post):\n",
    "    analysis = TextBlob(post)\n",
    "    return analysis.sentiment.polarity\n",
    "\n",
    "# Apply sentiment analysis\n",
    "df['sentiment'] = df['post'].apply(get_sentiment)\n",
    "\n",
    "# Filter posts mentioning the ticker\n",
    "df = df[df['post'].str.contains(ticker)]\n",
    "\n",
    "# Calculate the volume of mentions over time\n",
    "df.set_index('timestamp', inplace=True)\n",
    "volume_of_mentions = df.resample('5T').size()\n",
    "\n",
    "# Calculate the average sentiment over time\n",
    "average_sentiment = df.resample('5T')['sentiment'].mean()\n",
    "\n",
    "# Calculate the moving average of mentions (e.g., 3-period moving average)\n",
    "moving_average_mentions = volume_of_mentions.rolling(window=3).mean()\n",
    "\n",
    "# Display results\n",
    "print(\"Volume of Mentions:\\n\", volume_of_mentions)\n",
    "print(\"\\nAverage Sentiment:\\n\", average_sentiment)\n",
    "print(\"\\nMoving Average of Mentions:\\n\", moving_average_mentions)\n",
    "\n",
    "# Combine features into a single DataFrame\n",
    "social_media_buzz = pd.DataFrame({\n",
    "    'Volume of Mentions': volume_of_mentions,\n",
    "    'Average Sentiment': average_sentiment,\n",
    "    'Moving Average Mentions': moving_average_mentions\n",
    "})\n",
    "\n",
    "# Fill NaN values\n",
    "social_media_buzz.fillna(0, inplace=True)\n",
    "\n",
    "# Display the final Social Media Buzz DataFrame\n",
    "print(\"\\nSocial Media Buzz Features:\\n\", social_media_buzz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Institutional Holdings Change\n",
    "\n",
    "**Explanation:** This feature represents the change in the percentage of shares held by institutional investors over a recent period. Changes in institutional holdings can signal shifts in confidence among large, informed investors, which may precede significant stock movements.\n",
    "\n",
    "### Formulas and Techniques\n",
    "\n",
    "1. **Percentage Change Calculation**:\n",
    "   $$\n",
    "   \\text{Institutional Holdings Change} = \\frac{\\text{Current Institutional Holdings} - \\text{Previous Institutional Holdings}}{\\text{Previous Institutional Holdings}} \\times 100\n",
    "   $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Institutional Holdings Change:\n",
      "         date  institutional_holdings  institutional_holdings_change\n",
      "0 2023-01-01                    55.0                       0.000000\n",
      "1 2023-02-01                    57.2                       4.000000\n",
      "2 2023-03-01                    56.5                      -1.223776\n",
      "3 2023-04-01                    58.0                       2.654867\n",
      "4 2023-05-01                    59.0                       1.724138\n",
      "5 2023-06-01                    60.5                       2.542373\n",
      "\n",
      "Features DataFrame:\n",
      "         date  Institutional Holdings Change\n",
      "0 2023-01-01                       0.000000\n",
      "1 2023-02-01                       4.000000\n",
      "2 2023-03-01                      -1.223776\n",
      "3 2023-04-01                       2.654867\n",
      "4 2023-05-01                       1.724138\n",
      "5 2023-06-01                       2.542373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dusib\\AppData\\Local\\Temp\\ipykernel_29492\\3211795650.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['institutional_holdings_change'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame containing institutional holdings data\n",
    "data = {\n",
    "    'date': [\n",
    "        '2023-01-01', '2023-02-01', '2023-03-01', \n",
    "        '2023-04-01', '2023-05-01', '2023-06-01'\n",
    "    ],\n",
    "    'institutional_holdings': [\n",
    "        55.0, 57.2, 56.5, 58.0, 59.0, 60.5\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Calculate the percentage change in institutional holdings\n",
    "df['institutional_holdings_change'] = df['institutional_holdings'].pct_change() * 100\n",
    "\n",
    "# Fill NaN values resulting from the pct_change calculation\n",
    "df['institutional_holdings_change'].fillna(0, inplace=True)\n",
    "\n",
    "# Display the DataFrame with the new feature\n",
    "print(\"\\nInstitutional Holdings Change:\\n\", df)\n",
    "\n",
    "# Example of integrating this feature into a larger feature set\n",
    "features_df = pd.DataFrame({\n",
    "    'date': df['date'],\n",
    "    'Institutional Holdings Change': df['institutional_holdings_change']\n",
    "})\n",
    "\n",
    "# Display the final features DataFrame\n",
    "print(\"\\nFeatures DataFrame:\\n\", features_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Firm-Specific Information Delay (FSID)\n",
    "\n",
    "The study finds that information uncertainty amplifies the momentum effect, leading to stronger momentum in stocks with higher information uncertainty. Due to the lagged impact of firm-specific information on stock prices, companies with higher FSID exhibit higher return volatility and lower market efficiency.\n",
    "\n",
    "\n",
    "1. **Measure Information Uncertainty:** Use return volatility to identify and measure information uncertainty.\n",
    "2. **Strategy:** Go long on stocks with high momentum and high information uncertainty, and go short on stocks with low momentum and low information uncertainty.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculated Features:\n",
      "             info_uncertainty   momentum  rank_info_uncertainty  rank_momentum  \\\n",
      "date                                                                            \n",
      "2022-07-15          9.361564  39.140859                    6.0          148.0   \n",
      "2022-07-16          9.363633 -60.827077                    7.0           20.0   \n",
      "2022-07-17          9.364890 -57.718078                    8.0           24.0   \n",
      "2022-07-18          9.365148 -22.842810                    9.0           66.0   \n",
      "2022-07-19         36.822365  56.327887                   50.0          170.0   \n",
      "\n",
      "            alpha_signal  signal  \n",
      "date                              \n",
      "2022-07-15         888.0    12.0  \n",
      "2022-07-16         140.0     2.0  \n",
      "2022-07-17         192.0     4.0  \n",
      "2022-07-18         594.0     9.0  \n",
      "2022-07-19        8500.0    49.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample DataFrame containing stock prices\n",
    "data = {\n",
    "    'date': pd.date_range(start='2022-01-01', periods=200),\n",
    "    'close': np.random.rand(200) * 100\n",
    "}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Calculate daily returns\n",
    "df['returns'] = df['close'].pct_change()\n",
    "\n",
    "# Calculate information uncertainty (150-day rolling standard deviation of returns)\n",
    "df['info_uncertainty'] = df['returns'].rolling(window=150).std()\n",
    "\n",
    "# Calculate momentum (difference between close price and 12-day delayed close price)\n",
    "df['momentum'] = df['close'] - df['close'].shift(12)\n",
    "\n",
    "# Rank information uncertainty\n",
    "df['rank_info_uncertainty'] = df['info_uncertainty'].rank()\n",
    "\n",
    "# Rank momentum\n",
    "df['rank_momentum'] = df['momentum'].rank()\n",
    "\n",
    "# Calculate alpha signal\n",
    "df['alpha_signal'] = df['rank_info_uncertainty'] * df['rank_momentum']\n",
    "\n",
    "# Rank alpha signal\n",
    "df['rank_alpha_signal'] = df['alpha_signal'].rank()\n",
    "\n",
    "# Generate final signal\n",
    "df['signal'] = np.where(df['rank_alpha_signal'] > 0.5, -(1 - df['rank_alpha_signal']), df['rank_alpha_signal'])\n",
    "\n",
    "# Fill NaN values\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Display the final DataFrame with the calculated features\n",
    "print(\"\\nCalculated Features:\\n\", df[['info_uncertainty', 'momentum', 'rank_info_uncertainty', 'rank_momentum', 'alpha_signal', 'signal']].tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Coin stocks or Team stocks?\n",
    "\n",
    "**Background:**\n",
    "\n",
    "- **Coin Toss:** People expect reversals due to known probabilities.\n",
    "- **Predicting Team Championship:** Historical performance suggests momentum, predicting past champions to win again.\n",
    "\n",
    "In stocks, excessive trading for profit results in opposite outcomes:\n",
    "\n",
    "- **Team Stocks:** Likely to show reversal effects.\n",
    "- **Coin Stocks:** Likely to show momentum effects.\n",
    "\n",
    "**Predictability Factors:**\n",
    "\n",
    "- **Low Volatility:** Indicates stable prices, making future trends easier to predict.\n",
    "- **Decreasing Turnover Rate:** Indicates reduced investor disagreement, increasing predictability.\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "- **High Predictability (Coin Stocks):** Low volatility and decreasing turnover rate, likely to exhibit momentum effects.\n",
    "- **Low Predictability (Team Stocks):** High volatility and increasing turnover rate, likely to exhibit reversal effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            volatility  turnover_rate  rank_volatility  rank_turnover_rate  \\\n",
      "timestamp                                                                    \n",
      "2023-01-01         NaN       0.018313              NaN                62.0   \n",
      "2023-01-02         NaN       0.035054              NaN               134.0   \n",
      "2023-01-03         NaN       0.010486              NaN                13.0   \n",
      "2023-01-04         NaN       0.014926              NaN                42.0   \n",
      "2023-01-05         NaN       0.019828              NaN                72.0   \n",
      "...                ...            ...              ...                 ...   \n",
      "2023-05-26         NaN       0.020804              NaN                74.0   \n",
      "2023-05-27         NaN       0.039512              NaN               142.0   \n",
      "2023-05-28         NaN       0.007512              NaN                 2.0   \n",
      "2023-05-29         NaN       0.025845              NaN               105.0   \n",
      "2023-05-30    1.014945       0.008586              1.0                10.0   \n",
      "\n",
      "            alpha_signal  trading_signal  \n",
      "timestamp                                 \n",
      "2023-01-01           NaN              -1  \n",
      "2023-01-02           NaN              -1  \n",
      "2023-01-03           NaN              -1  \n",
      "2023-01-04           NaN              -1  \n",
      "2023-01-05           NaN              -1  \n",
      "...                  ...             ...  \n",
      "2023-05-26           NaN              -1  \n",
      "2023-05-27           NaN              -1  \n",
      "2023-05-28           NaN              -1  \n",
      "2023-05-29           NaN              -1  \n",
      "2023-05-30          11.0              -1  \n",
      "\n",
      "[150 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example DataFrame containing stock data\n",
    "data = {\n",
    "    'timestamp': pd.date_range(start='2023-01-01', periods=150, freq='D'),\n",
    "    'returns': np.random.randn(150),\n",
    "    'volume': np.random.randint(1000, 5000, size=150),\n",
    "    'shares_outstanding': np.random.randint(100000, 200000, size=150)\n",
    "}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Measure Volatility\n",
    "df['volatility'] = df['returns'].rolling(window=150).std()\n",
    "\n",
    "# Calculate Turnover Rate\n",
    "df['turnover_rate'] = df['volume'] / df['shares_outstanding']\n",
    "\n",
    "# Rank Volatility and Turnover Rate\n",
    "df['rank_volatility'] = df['volatility'].rank()\n",
    "df['rank_turnover_rate'] = df['turnover_rate'].rank()\n",
    "\n",
    "# Alpha Signal\n",
    "df['alpha_signal'] = df['rank_volatility'] + df['rank_turnover_rate']\n",
    "\n",
    "# Determine Trading Strategy\n",
    "df['trading_signal'] = df['alpha_signal'].apply(lambda x: 1 if x > df['alpha_signal'].median() else -1)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(df[['volatility', 'turnover_rate', 'rank_volatility', 'rank_turnover_rate', 'alpha_signal', 'trading_signal']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
